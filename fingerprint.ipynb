{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fingerprint.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1uw4dH2wKWmqX7Bic_TDtsPDiAB-ZNDRl",
      "authorship_tag": "ABX9TyPPrcvSJmScLcW/wzhixtlT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utsav-195/fingerprint-recognition-using-siamese-network/blob/master/fingerprint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrqyAzxChL2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQiznhCQhp4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "\n",
        "from tensorflow import keras\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4sU-MHbCo1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment(folder,file):\n",
        "  filename = folder + \"/\" + file\n",
        "  # loading in the images\n",
        "  image = imageio.imread(filename)\n",
        "\n",
        "  flip_vr=iaa.Flipud(p=1.0)\n",
        "  flip_vr_image= flip_vr.augment_image(image)\n",
        "\n",
        "  save_filename = folder + \"/\" + file.split(\".\")[0] + \"_flipped.png\"\n",
        "  cv2.imwrite(save_filename, flip_vr_image)\n",
        "\n",
        "  rotate = iaa.Affine(rotate=(50, -50))\n",
        "  rotated_image = rotate.augment_image(image)\n",
        "  save_filename = folder + \"/\" + file.split(\".\")[0] + \"_rotated1.png\"\n",
        "  cv2.imwrite(save_filename, rotated_image)\n",
        "\n",
        "  rotate = iaa.Affine(rotate=(50, -50))\n",
        "  rotated_image = rotate.augment_image(image)\n",
        "  save_filename = folder + \"/\" + file.split(\".\")[0] + \"_rotated2.png\"\n",
        "  cv2.imwrite(save_filename, rotated_image)\n",
        "\n",
        "  crop = iaa.Crop(percent=(0, 0.3)) # crop image\n",
        "  crop_image=crop.augment_image(image)\n",
        "  save_filename = folder + \"/\" + file.split(\".\")[0] + \"_cropped1.png\"\n",
        "  cv2.imwrite(save_filename, crop_image)\n",
        "\n",
        "  crop = iaa.Crop(percent=(0, 0.3)) # crop image\n",
        "  crop_image=crop.augment_image(image)\n",
        "  save_filename = folder + \"/\" + file.split(\".\")[0] + \"_cropped2.png\"\n",
        "  cv2.imwrite(save_filename, crop_image)\n",
        "\n",
        "  contrast=iaa.GammaContrast(gamma=2.0)\n",
        "  contrast_image =contrast.augment_image(image)\n",
        "  save_filename = folder + \"/\" + file.split(\".\")[0] + \"_bright1.png\"\n",
        "  cv2.imwrite(save_filename, contrast_image)\n",
        "\n",
        "  contrast=iaa.GammaContrast(gamma=1.4)\n",
        "  contrast_image =contrast.augment_image(image)\n",
        "  save_filename = folder + \"/\" + file.split(\".\")[0] + \"_bright2.png\"\n",
        "  cv2.imwrite(save_filename, contrast_image)\n",
        "\n",
        "  blur = iaa.GaussianBlur(sigma=4.0)\n",
        "  blur_image=blur.augment_image(image)\n",
        "  save_filename = folder + \"/\" + file.split(\".\")[0] + \"_blur1.png\"\n",
        "  cv2.imwrite(save_filename, blur_image)\n",
        "\n",
        "  blur = iaa.GaussianBlur(sigma=2.0)\n",
        "  blur_image=blur.augment_image(image)\n",
        "  save_filename = folder + \"/\" + file.split(\".\")[0] + \"_blur2.png\"\n",
        "  cv2.imwrite(save_filename, blur_image)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwtNBh1rjOsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dimen = 224\n",
        "\n",
        "dir_path = \"/content/drive/My Drive/fingerprint/images/\"\n",
        "out_path = \"/content/drive/My Drive/fingerprint/processed_images/\"\n",
        "model_path = \"/content/drive/My Drive/fingerprint/model/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCpqIaxJ_zF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub_dir_list = os.listdir(dir_path)\n",
        "\n",
        "images = []\n",
        "for i in range(len(sub_dir_list)):\n",
        "  # image_names = os.listdir(os.path.join(dir_path, sub_dir_list[i]))\n",
        "  # augment(os.path.join(dir_path, sub_dir_list[i]),image_names[0])\n",
        "  image_names = os.listdir(os.path.join(dir_path, sub_dir_list[i]))\n",
        "  for image_path in image_names:\n",
        "    path = os.path.join(dir_path, sub_dir_list[i], image_path )\n",
        "    try:\n",
        "      print(path)\n",
        "      image = Image.open(path)\n",
        "      resize_image = image.resize((dimen, dimen))\n",
        "      array_ = list()\n",
        "      for x in range(dimen):\n",
        "        sub_array = list()\n",
        "        for y in range(dimen):\n",
        "          sub_array.append(resize_image.load()[x, y])\n",
        "        array_.append(sub_array)\n",
        "      image_data = np.array(array_)\n",
        "      image = np.array(np.reshape(image_data, (dimen, dimen, 3))) / 255\n",
        "      images.append(image)\n",
        "    except:\n",
        "      print('WARNING : File {} could not be processed.'.format(path))\n",
        "\n",
        "images = np.array(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnU8l6rmf6WL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples_1 = []\n",
        "samples_2 = []\n",
        "labels = []\n",
        "\n",
        "for i in range(len(images)):\n",
        "  for j in range(len(images)):\n",
        "    samples_1.append(images[i])\n",
        "    samples_2.append(images[j])\n",
        "    t = i - i%10 +10\n",
        "    if t - 10 <= j < t:\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "\n",
        "X1 = np.array(samples_1)\n",
        "X2 = np.array(samples_2)\n",
        "Y = np.array(labels)\n",
        "\n",
        "np.save( '{}/x1.npy'.format( out_path ), X1 )\n",
        "np.save( '{}/x2.npy'.format( out_path ), X2 )\n",
        "np.save( '{}/y.npy'.format( out_path ) , Y )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iz-D8i3AFIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models , optimizers , losses ,activations , callbacks\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow.keras.backend as K\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class Recognizer (object) :\n",
        "\n",
        "\tdef __init__( self ):\n",
        "\n",
        "\t\t# tf.logging.set_verbosity( tf.logging.ERROR )\n",
        "\n",
        "\t\tself.__DIMEN = 224\n",
        "\n",
        "\t\tinput_shape = ( (self.__DIMEN**2) * 3 , )\n",
        "\t\tconvolution_shape = ( self.__DIMEN , self.__DIMEN , 3 )\n",
        "\t\tkernel_size_1 = ( 10 , 10 )\n",
        "\t\tkernel_size_2 = ( 7 , 7 )\n",
        "\t\tkernel_size_3 = ( 4 , 4 )\n",
        "\t\t# kernel_size_2 = ( 7 , 7 )\n",
        "\t\n",
        "\t\t# pool_size_1 = ( 3 , 3 )\n",
        "\t\t# pool_size_2 = ( 2 , 2 )\n",
        "\t\tstrides = 1\n",
        "\n",
        "\t\tseq_conv_model = [\n",
        "\n",
        "\t\t\tReshape( input_shape=input_shape , target_shape=convolution_shape),\n",
        "\n",
        "\t\t\tConv2D( 64, kernel_size=kernel_size_1 , strides=strides , activation='relu' ),\n",
        "\t\t\t# Conv2D( 32, kernel_size=kernel_size_1, strides=strides, activation='relu'),\n",
        "\t\t\tMaxPooling2D(),\n",
        "\n",
        "\t\t\tConv2D( 128, kernel_size=kernel_size_2 , strides=strides , activation='relu'),\n",
        "\t\t\t# Conv2D( 64, kernel_size=kernel_size_2 , strides=strides , activation='relu'),\n",
        "\t\t\tMaxPooling2D(),\n",
        "\n",
        "      Conv2D( 128, kernel_size=kernel_size_3 , strides=strides , activation='relu'),\n",
        "\t\t\t# Conv2D( 128, kernel_size=kernel_size_3 , strides=strides , activation='relu'),\n",
        "\t\t\tMaxPooling2D(),\n",
        "\n",
        "\t\t\tConv2D( 256, kernel_size=kernel_size_3 , strides=strides , activation='relu'),\n",
        "\t\t\t# Conv2D( 128, kernel_size=kernel_size_3 , strides=strides , activation='relu'),\n",
        "\n",
        "\t\t\tFlatten(),\n",
        "\n",
        "\t\t\tDense( 1024 , activation='relu' ),\n",
        "\t \t\tDense( 1024 , activation=activations.sigmoid )\n",
        "\n",
        "\t\t]\n",
        "\n",
        "\t\tseq_model = tf.keras.Sequential( seq_conv_model )\n",
        "\n",
        "\t\tinput_x1 = Input( shape=input_shape )\n",
        "\t\tinput_x2 = Input( shape=input_shape )\n",
        "\n",
        "\t\toutput_x1 = seq_model( input_x1 )\n",
        "\t\toutput_x2 = seq_model( input_x2 )\n",
        "\n",
        "\t\tdistance_euclid = Lambda( lambda tensors : K.abs( tensors[0] - tensors[1] ))( [output_x1 , output_x2] )\n",
        "\t\toutputs = Dense( 1 , activation=activations.sigmoid) ( distance_euclid )\n",
        "\t\tself.__model = models.Model( [ input_x1 , input_x2 ] , outputs )\n",
        "\n",
        "\t\tself.__model.compile( loss=losses.binary_crossentropy , optimizer=optimizers.Adam(lr=0.00003))\n",
        "\n",
        "\n",
        "\n",
        "\tdef fit(self, X, Y ,  hyperparameters  ):\n",
        "\t\tinitial_time = time.time()\n",
        "\t\tself.__model.fit( X  , Y ,\n",
        "\t\t\t\t\t\t batch_size=hyperparameters[ 'batch_size' ] ,\n",
        "\t\t\t\t\t\t epochs=hyperparameters[ 'epochs' ] ,\n",
        "\t\t\t\t\t\t callbacks=hyperparameters[ 'callbacks'],\n",
        "\t\t\t\t\t\t validation_data=hyperparameters[ 'val_data' ]\n",
        "\t\t\t\t\t\t )\n",
        "\t\tfinal_time = time.time()\n",
        "\t\teta = ( final_time - initial_time )\n",
        "\t\ttime_unit = 'seconds'\n",
        "\t\tif eta >= 60 :\n",
        "\t\t\teta = eta / 60\n",
        "\t\t\ttime_unit = 'minutes'\n",
        "\t\tself.__model.summary( )\n",
        "\t\tprint( 'Elapsed time acquired for {} epoch(s) -> {} {}'.format( hyperparameters[ 'epochs' ] , eta , time_unit ) )\n",
        "\n",
        "\n",
        "\tdef prepare_images_from_dir( self , dir_path , flatten=True ) :\n",
        "\t\timages = list()\n",
        "\t\timages_names = os.listdir( dir_path )\n",
        "\t\tfor imageName in images_names :\n",
        "\t\t\t# print(imageName)\n",
        "\t\t\timage = Image.open(dir_path + imageName)\n",
        "\t\t\tresize_image = image.resize((self.__DIMEN, self.__DIMEN))\n",
        "\t\t\tarray = list()\n",
        "\t\t\tfor x in range(self.__DIMEN):\n",
        "\t\t\t\tsub_array = list()\n",
        "\t\t\t\tfor y in range(self.__DIMEN):\n",
        "\t\t\t\t\tsub_array.append(resize_image.load()[x, y])\n",
        "\t\t\t\tarray.append(sub_array)\n",
        "\t\t\timage_data = np.array(array)\n",
        "\t\t\timage = np.array(np.reshape(image_data,(self.__DIMEN, self.__DIMEN, 3)))\n",
        "\t\t\timages.append(image)\n",
        "\n",
        "\t\tif flatten :\n",
        "\t\t\timages = np.array(images)\n",
        "\t\t\treturn images.reshape( ( images.shape[0]  , self.__DIMEN**2 * 3  ) ).astype( np.float32 )\n",
        "\t\telse:\n",
        "\t\t\treturn np.array(images)\n",
        "\n",
        "\n",
        "\n",
        "\tdef evaluate(self , test_X , test_Y  ) :\n",
        "\t\treturn self.__model.evaluate(test_X, test_Y)\n",
        "\n",
        "\n",
        "\tdef predict(self, X  ):\n",
        "\t\tpredictions = self.__model.predict( X  )\n",
        "\t\treturn predictions\n",
        "\n",
        "\n",
        "\tdef summary(self):\n",
        "\t\tself.__model.summary()\n",
        "\n",
        "\tdef save_model(self , file_path ):\n",
        "\t\tself.__model.save(file_path )\n",
        "\n",
        "\n",
        "\tdef load_model(self , file_path ):\n",
        "\t\tself.__model = models.load_model(file_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsDtTHOXAKeX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13ab7dc7-6d13-4261-f86a-945a2caa29a5"
      },
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "data_dimension = 224\n",
        "\n",
        "X1 = np.load('{}/x1.npy'.format( out_path ))\n",
        "X2 = np.load('{}/x2.npy'.format( out_path ))\n",
        "Y = np.load('{}/y.npy'.format( out_path ))\n",
        "\n",
        "X1 = X1.reshape( ( X1.shape[0]  , data_dimension**2 * 3  ) ).astype( np.float32 )\n",
        "X2 = X2.reshape( ( X2.shape[0]  , data_dimension**2 * 3  ) ).astype( np.float32 )\n",
        "\n",
        "print( X1.shape )\n",
        "print( X2.shape )\n",
        "print( Y.shape )\n",
        "\n",
        "recognizer = Recognizer()\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# checkpointer to save the best model\n",
        "checkpointer = ModelCheckpoint(filepath='{}/model_test5.h5'.format(model_path), monitor='loss', verbose=1, save_best_only=True)\n",
        "\n",
        "parameters = {\n",
        "    'batch_size' : 50,\n",
        "    'epochs' : 30,\n",
        "    'callbacks' : checkpointer,\n",
        "    'val_data' : None\n",
        "}\n",
        "\n",
        "recognizer.fit( [ X1 , X2 ], Y, hyperparameters=parameters)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2500, 150528)\n",
            "(2500, 150528)\n",
            "(2500,)\n",
            "Epoch 1/20\n",
            " 2/50 [>.............................] - ETA: 12s - loss: 0.6931WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0418s vs `on_train_batch_end` time: 0.4507s). Check your callbacks.\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5580\n",
            "Epoch 00001: loss improved from inf to 0.55796, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 30s 603ms/step - loss: 0.5580\n",
            "Epoch 2/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4466\n",
            "Epoch 00002: loss improved from 0.55796 to 0.44657, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 655ms/step - loss: 0.4466\n",
            "Epoch 3/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3916\n",
            "Epoch 00003: loss improved from 0.44657 to 0.39160, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.3916\n",
            "Epoch 4/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.3313\n",
            "Epoch 00004: loss improved from 0.39160 to 0.33134, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.3313\n",
            "Epoch 5/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2822\n",
            "Epoch 00005: loss improved from 0.33134 to 0.28224, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 663ms/step - loss: 0.2822\n",
            "Epoch 6/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.2348\n",
            "Epoch 00006: loss improved from 0.28224 to 0.23477, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 661ms/step - loss: 0.2348\n",
            "Epoch 7/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1856\n",
            "Epoch 00007: loss improved from 0.23477 to 0.18562, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 667ms/step - loss: 0.1856\n",
            "Epoch 8/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1547\n",
            "Epoch 00008: loss improved from 0.18562 to 0.15473, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 34s 674ms/step - loss: 0.1547\n",
            "Epoch 9/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1400\n",
            "Epoch 00009: loss improved from 0.15473 to 0.13998, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 664ms/step - loss: 0.1400\n",
            "Epoch 10/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.1067\n",
            "Epoch 00010: loss improved from 0.13998 to 0.10665, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 662ms/step - loss: 0.1067\n",
            "Epoch 11/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0756\n",
            "Epoch 00011: loss improved from 0.10665 to 0.07560, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 664ms/step - loss: 0.0756\n",
            "Epoch 12/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0675\n",
            "Epoch 00012: loss improved from 0.07560 to 0.06746, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 34s 681ms/step - loss: 0.0675\n",
            "Epoch 13/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0468\n",
            "Epoch 00013: loss improved from 0.06746 to 0.04682, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 35s 694ms/step - loss: 0.0468\n",
            "Epoch 14/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0408\n",
            "Epoch 00014: loss improved from 0.04682 to 0.04080, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 34s 676ms/step - loss: 0.0408\n",
            "Epoch 15/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0369\n",
            "Epoch 00015: loss improved from 0.04080 to 0.03694, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 663ms/step - loss: 0.0369\n",
            "Epoch 16/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0338\n",
            "Epoch 00016: loss improved from 0.03694 to 0.03377, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 670ms/step - loss: 0.0338\n",
            "Epoch 17/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0323\n",
            "Epoch 00017: loss improved from 0.03377 to 0.03226, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 33s 664ms/step - loss: 0.0323\n",
            "Epoch 18/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0299\n",
            "Epoch 00018: loss improved from 0.03226 to 0.02995, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 35s 694ms/step - loss: 0.0299\n",
            "Epoch 19/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0282\n",
            "Epoch 00019: loss improved from 0.02995 to 0.02820, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 35s 694ms/step - loss: 0.0282\n",
            "Epoch 20/20\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.0274\n",
            "Epoch 00020: loss improved from 0.02820 to 0.02740, saving model to /content/drive/My Drive/fingerprint/model/model_test4.h5\n",
            "50/50 [==============================] - 34s 679ms/step - loss: 0.0274\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150528)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 150528)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 1024)         107115840   input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 1024)         0           sequential[0][0]                 \n",
            "                                                                 sequential[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            1025        lambda[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 107,116,865\n",
            "Trainable params: 107,116,865\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Elapsed time acquired for 20 epoch(s) -> 11.31226752201716 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRlBCCw6ZyKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "f2bb1ebc-29b7-4591-ac48-cba464c3adda"
      },
      "source": [
        "recognizer = Recognizer()\n",
        "recognizer.load_model('{}/model_test5.h5'.format(model_path))\n",
        "\n",
        "test_images = recognizer.prepare_images_from_dir(\"/content/drive/My Drive/fingerprint/test_images/\")\n",
        "class_images = \"/content/drive/My Drive/fingerprint/images/\"\n",
        "\n",
        "scores = []\n",
        "labels = []\n",
        "for image in test_images:\n",
        "    # print(image)\n",
        "    label = []\n",
        "    score = []\n",
        "    for class_name in os.listdir(class_images):\n",
        "      samples = recognizer.prepare_images_from_dir(\"/content/drive/My Drive/fingerprint/images/\"+class_name+\"/\")\n",
        "      for sample in samples:\n",
        "        # print(sample)\n",
        "        image, sample = image.reshape((1, -1)), sample.reshape((1 ,-1))\n",
        "        score.append(recognizer.predict([image, sample])[0])\n",
        "        label.append(class_name)\n",
        "    labels.append(label)\n",
        "    scores.append(score)\n",
        "\n",
        "scores = np.array(scores)\n",
        "labels = np.array(labels)\n",
        "\n",
        "for i in range(test_images.shape[0]) :\n",
        "    index = np.argmax(scores[i])\n",
        "    label_ = labels[i][index]\n",
        "    print( 'IMAGE {} is {} with confidence of {}'.format( i+1  , label_ , scores[i][index][0] ) )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IMAGE 1 is thumb with confidence of 0.9975006580352783\n",
            "IMAGE 2 is first with confidence of 0.9981439709663391\n",
            "IMAGE 3 is middle with confidence of 0.9968104958534241\n",
            "IMAGE 4 is pinky with confidence of 0.9980166554450989\n",
            "IMAGE 5 is ring with confidence of 0.9958359003067017\n",
            "IMAGE 6 is thumb with confidence of 0.9984050989151001\n",
            "IMAGE 7 is pinky with confidence of 0.977330207824707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYoumfuJJmps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}